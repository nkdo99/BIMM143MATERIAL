---
title: 'Lab 9: Mini Project'
author: 'Nicholas Do (PID: A15053002)'
date: "10/26/2021"
output: pdf_document
---

```{r}
fna.data <- "WisconsinCancer.csv"

wisc.df <- read.csv(fna.data, row.names=1)
#Examine data
head(wisc.df)
```



Create a new Data frame that omits the first column:
```{r}
#diagnosis vector
diagnosis <- factor(wisc.df[,1])


#Remove first column from analysis
wisc.data <- wisc.df[,-1]
head(wisc.data)

```

```{r}
diagnosis
```

> Q1. How many observations are in this dataset?

There are 569 observations within the data set.

> Q2. How many of the observations have a malignant diagnosis?

```{r}
#count <- which(diagnosis == "M")
count <- grep("M", diagnosis)
length(count)

#or
#table(diagnosis)
```
Thus there are 212 observations with a malignant diagnosis.


> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length(grep("_mean", colnames(wisc.data)))
```
10 variables are suffixed with mean

2. Performing PCA
```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```
```{r}
# Perform PCA on wisc.data
wisc.pr <- prcomp(wisc.data, scale=TRUE)
# Look at summary of results
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?


PC1 has a proportion of 0.4427, or 44.27%.

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

Three PCs (PC1 - PC3) are required to describe at least 70% of the original variance,
as the cumulative proportion up to PC3 is 72.636%.


> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

Seven PCs (PC1 - PC7) are required to describe at least 90% of the original variance,
as the cumulative proportion up to PC7 is 91.010%.


Plot the Graph:
```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is very crowded and compact, and there is way too much information presented
to be able to understand.



Make our own plot:
```{r}
# Scatter plot observations by components 1 and 2
plot( wisc.pr$x[,1:2] , col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot( wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis , 
     xlab = "PC1", ylab = "PC3")
```
For this plot the values are a lot closer together, there is less variance
so it is more difficult to distinguish the groups. 



Create a better plot using ggplot2:
```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col= diagnosis) + geom_point()
```


Calculating Variance:
```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Calculate variance of each PC:
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


Alternative Scree Plot
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

ggplot2 graph
```{r}

#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation[,1]
```
concave.points_mean is -0.26085376.


> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

The minimum number of PCs required to explain 80% of the variance is 5 PCs, 
since the cumulative proportion of variance from PC1 - PC5 is 84.734.

```{r}
summary(wisc.pr)
```


3. Hierarchical clustering
```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)

# Calculate Euclidean distance
data.dist <- dist(data.scaled)

# Create a hierarchical clustering model using complete linkage
wisc.hclust <- hclust(data.dist, method = "complete")
```

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```
Using an abline with a height of 20 represents the clustering model at a point with 4 clusters.


Select the number of clusters
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4, h = 20)

table(wisc.hclust.clusters, diagnosis)

```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 5)

table(wisc.hclust.clusters, diagnosis)
```
For 5 clusters, I think that the cluster vs diagnoses match is better because 
it separates the benign and malignant cells better. 


> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.


```{r}
# Experimenting with different methods
wisc.hclust.methods <- hclust(data.dist, method = "ward.D2")
wisc.hclust.methods.clusters <- cutree(wisc.hclust.methods, k = 5)


plot(wisc.hclust.methods)
table(wisc.hclust.methods.clusters, diagnosis)
```
I think that ward.D2 gives the best result because as explained in the side note 
for the lab, ward.D2 creates clusters with minimum variance.


Combining Methods
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method="ward.D2")
summary(wisc.pr.hclust)
plot(wisc.pr.hclust)
abline(h=60, col='red')
```

#Find out what the main clusters are
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)

#Cross table, comparison of diagnosis and cluster group
table(grps, diagnosis)
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)

```

Reorder the levels
```{r}
g <- as.factor(grps)
levels(g)
g <- relevel(g,2)
levels(g)

# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```
#4. k-means
```{r}
wisc.km <- kmeans(data.scaled, centers= 2, nstart= 20)
table(wisc.km$cluster, diagnosis)
```






#Optional RGL
```{r}
#library(rgl)
#plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=grps)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
#plot(wisc.pr.hclust)

wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```




```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```
> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

The new model does a good job at separating the benign from the malignant cells, leaving only a
few of the opposite within each cluster. 


> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```
The previous k-means and hierarchical clustering models have a higher variance within 
their clusters compared to the new model, but they still do a fairly good job at
separating the diagnoses. 

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

```{r}
#Sensitivity
table(diagnosis)
table(wisc.pr.hclust.clusters, diagnosis)
wisc.pr.hclust.clusters.sense = 188 / 212
wisc.pr.hclust.clusters.sense

wisc.km.sense = 175/ 212
wisc.km.sense

wisc.hclust.sense = 165 / 212
wisc.hclust.sense

```

```{r}
#Specificity
table(diagnosis)
table(wisc.pr.hclust.clusters, diagnosis)
wisc.pr.hclust.clusters.spec = 329 / (329+28)
wisc.pr.hclust.clusters.spec

wisc.km.spec = 356 / (356+1)
wisc.km.spec

wisc.hclust.spec = 343 / (343+14)
wisc.hclust.spec
```



The prhclust method gave the best sensitivity, and the kmeans method gave the best specificity.

#7. Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```
```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

I would prioritize patient 2 because their cells lie much closer towards the malignant data that we have.











